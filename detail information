Forest fires are a common occurrence worldwide due to climate change, which results in severe economic losses and ecological destruction (Bot 2022; Castelli et al. 2015). Forest fires can be natural or man-made forest fires and summer forest fires caused by debris and other biomes, as well as human negligence. Even though, wildfires can benefit local vegetation, animals, and ecosystems, but they can also cause major damage to property and human life. In recent years, the frequency of forest fire accidents has been continuously increasing. Hence, there has been a rise in interest of implementing systems for automated observation and detection of forest fires, as a means of protecting forests from destruction.

There are a number of conventional and cutting-edge fire and smoke detection techniques that have been proposed to reduce damage brought on by fire disasters. Sensor-based and vision-based smoke detection systems have garnered a lot of interest in the research community among these techniques. Based on sensor types and applications, the fire detection technique is split into five basic groups: smoke-sensitive, light-sensitive, gas-sensitive, temperature-sensitive, and composite (Saeed et al. 2018). Temperature and smoke sensors are frequently used for this purpose (Kizilkaya 2022). The sensor-based approach has significant limitations in terms of detection range and detection speed (Park and Ko 2020). Since fire spreads quickly, it is important to keep the delay as short as possible. Then, as video surveillance technology came up, researchers gathered fire images and used their color characteristics to look for fires. Orange or yellow flames moving side to side are the most common visual representations of fire in videos and images. Soot or burnt particles can be seen in smoke as a blend of white, gray, and black plumes. Smoke detection in videos and images has its own set of difficulties. To be effective, a system must be able to find the difference between images that truly contain the fire and those that appear to have flames but are not. False alarm rates are higher when using simple color features for fire detection (Hu et al. 2022). So, in order to capture the properties of a fire, such as color, shape, flickering, frequency, and dynamic textures, image processing-based methods have been developed. These techniques detect fire by utilizing the RGB, YUV, YCbCr, and CIELab color spaces (Yang 2022; Al-Duryi 2022; Fang 2022; Seydi 2022).

Along with color information, motion data has also been incorporated. The reliance on fire detection technology has grown as a result of methods discussed in (Anh et al. 2022). But, the use of surveillance camera images has introduced a new image processing issue. Video cameras produce a continuous stream of images that must be stored and processed which would be more expensive. As a result, several approaches and systems for fire detection have been presented to make the system as precise and autonomous as feasible. As video surveillance technology expanded in recent years, image processing technology in machine vision also advanced (Zhao et al. 2022), speeding up transmission and sensing. As a result, computer vision-based fire and smoke detection technology has been developed, enabling a greater variety of fire detection approaches. By utilizing video surveillance to collect and extract features from the images of fire and smoke, a computer vision-based fire and smoke detection technology can develop a detection model that relies on these images. Hence, to assess the presence of fire and smoke in images, traditional machine learning and deep learning-based computer vision approaches have been advocated.

Machine learning has been used in a range of applications, including forest fire prediction and detection. (Abid 2021; Arif et al. 2021; Ko et al. 2009; Kong et al. 2016; Bouguettaya et al. 2022; Friggens 2021) provides a wide-ranging overview of the use of machine learning techniques for forest fire detection. Machine learning-based fire detection algorithms rely on manually extracting visible information from images. These characteristics only focus on the shallow characteristics of the flame, which could lead to data loss when extracting manually. Unlike machine learning algorithms, deep learning (Schmidhuber 2015) can automatically extract and learn complicated feature representations. CNN’s success in image classification and deep learning’s breakthrough growth in computer vision (Ha 2018; Mao et al. 2018; Saeed et al. 2020; Yang et al. 2019; Li et al. 2020; Majid et al. 2022; Fouda 2022) make fire detection a promising area of research. CNN-based methods use frames from surveillance systems as input, and the prediction result is sent to an alert system. Inception (Szegedy 2015), VGGNet (Simonyan 2014), Xception (Chollet 2017), and many more CNN variants have been applied in fire detection tasks.

Classifying images of fire and smoke has proven difficult in the past due to the large parameter space used by off-the-self deep architectures such as VGG16, DenseNet, Inception, and Xception, among other options. When faced with large parameter spaces, however, transfer learning may be a viable option. Knowledge learned in one domain can then be transferred to another where there is fewer data. Even with a few images, deep architectures using pre-trained models can be built (Best et al. 2020). When trained on a large number of examples, deep learning models outperform (Tian 2015). When training samples are inadequate, overfitting and slipping into a local optimum can occur (Krizhevsky et al. 2017). Transfer learning can aid us in resolving such situations. Many computer vision tasks, such as object detection and face recognition, have seen recent success with deep learning, but the use of these approaches for fire detection has been sparse. Fire detection research may be lacking due to a shortage of data for deep learning models. This has motivated us to focus on the collection of a considerable quantity of fire/smoke images from different sources. Further, even if a pre-trained CNN classifier is trained to classify particular types of tasks using transfer learning, the fact is that the model can work well on recognizing tasks on which it has been trained, but it underperforms when a new, but similar task is given. This is known in machine learning, as “the catastrophic forgetting phenomenon.” This phenomenon further motivated us to explore the concept of LwF for detecting forest fire /smoke images from a new dataset. The focus of the proposed research work is highlighted below:

Research focus
Following are the research questions we would like to address in this work.

RQ1: How are pre-trained models adaptable?

To address this question, we compared the performance of pre-trained models as feature extractors and fine tuners.

RQ2: How well do pre-trained models categorize new dataset images?

To address this, we refined and trained numerous pre-trained CNN models and compared them to models employed solely as feature extractors.

RQ3: To what extent may fine-tuning hyperparameters for various CNN models be effective?

Because the choice of values of hyperparameters is critical for evaluating a model’s performance, we employed Bayesian Optimization to determine the ideal values for the hyperparameters.

RQ4: Is the knowledge gained by models from one dataset transferable to another?

We used BoWFire, a small yet challenging dataset, to investigate this issue.

The objective of this work is to build a set of models that automatically recognize and detect the presence of fire/smoke in images using pre-trained CNN models like VGG16, InceptionV3, and Xception architectures. By utilizing two techniques namely freezing the convolutional base (feature extractor) and training some convolutional layers while freezing others (fine-tuner), we can use previously learned models for new tasks. Furthermore, we use the LwF, which trains the network using only new task data while preserving its baseline capabilities. Additionally, Bayesian optimization is used in this study to identify the best hyperparameter configuration because it is crucial and challenging to select the right hyperparameters when training CNN architectures.

Research contributions
The contributions to this work include:

(i)
Examined various pre-trained CNN models and identified the methods to explore the pre-trained models.

(ii)
Developed low-cost computation models and analyzed the performance of the variants of CNNs.

(iii)
Optimized the values for various hyperparameters of CNN models using Bayesian optimization.

(iv)
Transferred the knowledge learned by the proposed models to a standard, but challenging dataset, BoWFire using LwF.

As far as we are aware, there is not any work in the literature that discusses transfer learning utilizing LWF, fine-tuning procedures, and optimization approach for categorizing fire and smoke images. The remainder of the article is organized as follows: the “Literature survey” section discusses recent developments in the field of fire and smoke detection. In the “Materials and methods” section, we discuss the dataset, deep neural network architectures, tuning of hyperparameters, and fine-tuning procedures. This section also introduces LwF. The “Experiments and results” section presents the experimental results. The “Findings and discussion” section summarizes the findings from the study. In the “Findings and discussion” section, an in-depth look at how the images were wrongly classified by the proposed models is also given. Finally, in the “Conclusion and feature direction” section, we recapitulate our study and give a direction for future works.

Literature survey
This section discusses the many research efforts that have been conducted to build models for detecting fire and smoke detection systems. With the growth of AI, numerous research attempts have been made to detect the presence of fire/smoke in images using machine learning and deep learning models. However, in this work, we examined CNN-based models for fire/smoke detection.

In a range of computer-based vision applications, such as visual recognition and image classification, the introduction of CNNs has resulted in significant performance gains. By recognizing hand-written characters, LeNet-5, a CNN algorithm presented by LeCun et al. (1998), achieved one of the first successful outcomes in this field. Due to the availability of large-scale datasets and the advent of incredibly powerful GPUs, researchers have lately been able to generate extremely deep CNNs. For instance, Krizhevsky et al. (Best et al. 2020) introduced AlexNet, a deep CNN network that performed exceptionally well in the 2012 ImageNet Challenge. Additionally, numerous CNN variations have exhibited exceptional performance in image categorization (Namozov and Im Cho 2018).

CNNs in smoke and fire detection were examined in a survey (Li and Zhao 2020). Further, this effort also discussed current datasets and overviews of modern computer vision approaches. In conclusion, the authors highlighted the obstacles and potential solutions for furthering the development of CNNs in this field. Mahmoud et al. (2022) developed a time-efficient fire detection system using CNN and transfer learning. This model leveraged a CNN architecture with an acceptable computing time for real-time applications and asserted that the proposed model required less training and classification time than existing models in the literature due to the use of transfer learning. Bari et al. (Bari 2021) used their curated v3-base dataset of online and recorded videos to fine-tune the InceptionV3 and MobileNetV2 models. The authors found that when trained on a small dataset, transfer learned models outperform fully trained models. The authors of (Cheng 2021) developed an approach using a Fast Regional Convolutional Neural Network (Fast R–CNN). A selective search method was used to locate candidate images from the sample images. As proven by the results, fast R-CNN smoke detection showed an increased detection rate and decreased false alarms. Pu and Zhao (Li and Zhao 2020) proposed novel fire detection methods based on advanced object identification CNN models such as Faster-RCNN, R–FCN, YOLO v3 etc. A comparison of proposed and existing fire detection algorithms indicated that those based on object detection, CNNs outperformed other algorithms in terms of accuracy. And, YOLOv3-based model gave an average precision of 83.7%, which is much greater than the precision of the other proposed algorithms.

Sousa et al. (2020) summarized recent research attempts to present the common challenges and limitations of these approaches, as well as issues about the dataset quality. Furthermore, they devised a method for transfer learning and utilizing data augmentation techniques that were validated using a tenfold cross-validation scheme. The proposed framework enabled the use of an open-source dataset containing images from over 35 real-world fire events. Unlike video-based works, this dataset contains a high degree of variation between samples, allowing us to test the method in a variety of real-world scenarios. Fernandez et al. (2021) demonstrated a system that can acquire real-time images and process them to perform object detection tasks using RetinaNet and Faster-RCNN. To help contain wildfires, this system is capable of detecting smoke plumes over a large area and communicating with and alerting authorities. Luo et al. (2018) developed a smoke detection system using a CNN and the motion characteristics of smoke. To begin, they identified candidate regions using a combination of the background dynamic update and a priori dark channel technique. Following that, using a CNN, the candidate region’s features were extracted automatically.

With the use of optical images and retrained VGG16 and ResNet50 models, the authors of (Sharma 2017) were able to distinguish between images that included and did not contain the fire. It’s worth noting that they created an unbalanced training dataset that included a higher proportion of non-fire images. For fire detection and disaster management, the authors of (Muhammad et al. 2018) integrated AlexNet as a foundation architecture. This system incorporated an adaptive priority mechanism for surveillance cameras, enabling high-resolution cameras to be activated to confirm the fire and assess the data in real time. Inspired by GoogleNet architecture, Muhammad et al. (2018) proposed a fine-tuned CNN model for fire detection in surveillance systems. The tests demonstrated that the suggested architecture outperformed both existing hand-crafted feature-based and AlexNet-based fire detection systems. The authors of (Nguyen et al. 2021) suggested a unique approach for fire detection based on the use of CNN to extract both spatial and temporal information for fire classification from video image sequences. The system extracted image features using a CNN network and then classified them using short- and long-term stages. Experiments on readily accessible public datasets indicated encouraging performance outcomes when compared to prior studies.

Qin et al. (2021) suggested a system for detecting and locating the firing position in images using a depth-wise separable CNN and YOLOv3. To begin, fire images have been classified using a depth-wise separable CNN, which greatly reduces detection time while retaining detection accuracy. Second, YOLOv3 is utilized to locate the position of fire from the images labeled as fire, thus avoiding the problem of detection accuracy being degraded when YOLOv3 is used. Simultaneously, for images without fire, the detection time for target regression is greatly lowered. Validated against a publicly available network database, the tests obtained a detection precision of approximately 98%. In the work by (Jeon et al. 2021), the authors developed a framework for multi-scale prediction using the feature maps created by densely stacked convolutional layers. This approach presented a feature-squeeze block as a mechanism for incorporating feature maps with varying scales into the final forecast. The feature-squeeze block efficiently utilized the multi-scale prediction information by spatially and channel-wise compressing the feature maps. The suggested strategy outperformed currently available CNN-based methods in experiments.

A CNN-based fire detection system appropriate for power-constrained devices was proposed by Vinicius et al. (de 2022). To decrease the computational cost of a deep detection network while attempting to maintain its original performance, this method involves training the network and then eliminating its less crucial convolutional filters. Dampage (2022) presented a system and technique for using a wireless sensor network to identify forest fires in their earliest stages. In addition, for more precise fire detection, a machine learning regression model is proposed. In their work, Dogan et. al.(2022) suggested deep learning models using ResNet and InceptionNet to detect fire from images. These models have been used for extracting the features and these features have been classified using SVM. The authors demonstrated that ResNet gave better performance.

From the above review works, it is clear that CNNs offer tremendous promise for fire detection and can aid in the creation of a robust system capable of significantly reducing human and financial loss due to fires. From the investigation of the literature, we find that even though, the detection of forest fire/smoke from images has been focused on, no work has focused on the forgetting phenomenon when the trained models are used for new tasks of fire/smoke images. Additionally, some gaps in the application of CNN for fire and smoke detection remain including faster training, parameter efficiency, hyperparameter tuning, and transfer learning over the new datasets. Although a few experiments employed transfer learning to expedite the training process, none of the studies mentioned above attempted to tune hyperparameters. To recap, we create a few classification models that can differentiate between fire and smoke in images by combining deep learning and transfer learning with hyperparameter tuning, reducing time and ensuring early detection. In addition, we employ LwF to keep the original network capabilities while training the models on a new data.

Materials and methods
Dataset description and augmentation
Geostationary weather satellites including MODIS, VIIRS, Copernicus Sentinel-2, and Landsat-8 were used to construct the dataset for the proposed study (Kaulage 2022). These satellites are used for fire detection all around the world due to their excellent temporal precision and ability to detect fires in far-off locations. In addition to images from Google and Kaggle (https://www.kaggle.com/datasets/phylake1337/fire-dataset, http://github.com/aiformankind/wildfire-smoke-dataset, http://www.kaggle.com/datasets/dataclusterlabs/fire-and-smoke-dataset), satellite imagery of the forest fire has also been compiled. Manual labeling has been applied to the images, designating them as Fire, No Fire, Smoke, and Smoke Fire. There are 4800 images in the obtained dataset. To expand the number of images, image augmentation techniques such as shifting, flipping, rotating, scaling, blurring, padding, cropping, translation, and affine modification were applied. The collection comprises 6,911 images after augmentation. Then, the datasets for training, validation, and testing were divided, with 80% of the dataset going toward training the classifier and 10% going toward testing and validation. The distribution of images in the dataset for training, testing, and validation is shown in Table 1. Sample images from the dataset are shown in Fig. 1.
